{
	"AI": {
		"DefaultProvider": "Ollama",
		"OpenAI": {
			"ApiKey": "",
			"BaseUrl": "https://api.openai.com/v1",
			"EmbeddingModel": "text-embedding-3-small",
			"CompletionModel": "gpt-4o-mini",
			"MaxTokens": 1000,
			"Temperature": 0.7
		},
		"AzureOpenAI": {
			"ApiKey": "<AzureOpenAI-ApiKey>",
			"Endpoint": "https://<AzureOpenAI-Endpoint>.openai.azure.com/",
			"EmbeddingDeploymentName": "text-embedding-3-small",
			"CompletionDeploymentName": "gpt-4o-mini",
			"MaxTokens": 1000,
			"Temperature": 0.7
		},
		"Ollama": {
			"BaseUrl": "http://localhost:11434",
			"EmbeddingModel": "nomic-embed-text",
			"CompletionModel": "llama3.2",
			"MaxTokens": 1000,
			"Temperature": 0.7
		}
	},
	"BM25": {
		"Provider": "ElasticSearch",
		"ElasticSearch": {
			"IndexName": "hyde-search"
		}
	},
	"HyDE": {
		"HydeWeight": 0.7,
		"TraditionalWeight": 0.3,
		"MaxResults": 10,
		"SimilarityThreshold": 0.1,
		"HydePromptTemplate": "Write a passage that would answer this question: {query}\n\nPassage:"
	},
	"HybridSearch": {
		"BM25Weight": 0.3,
		"HydeWeight": 0.7,
		"MaxResults": 10,
		"ScoreThreshold": 0.01,
		"EnableBM25": true,
		"EnableHyDE": true,
		"NormalizationStrategy": "MinMax",
		"RerankingStrategy": "ReciprocalRankFusion",
		"RrfK": 60.0
	},
	"Logging": {
		"LogLevel": {
			"Default": "Information",
			"Microsoft": "Warning",
			"Microsoft.Hosting.Lifetime": "Information"
		}
	}
}